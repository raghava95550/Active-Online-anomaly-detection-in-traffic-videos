{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import datetime\n",
    "from sklearn import cluster,datasets\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.cluster import KMeans\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_reading(file_path):\n",
    "    #reading annotations file\n",
    "    ann_file = open(file_path,\"r\") #opening file in read mode only\n",
    "    strings = [x.strip() for x in ann_file.readlines()]\n",
    "    stimes=[]\n",
    "    etimes=[]\n",
    "    for i in range(len(strings)):\n",
    "        s1,s2=strings[i].split(\"-\")\n",
    "        stimes.append(s1.strip())\n",
    "        etimes.append(s2.strip())\n",
    "    return stimes,etimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(stime,etime,abnormal_stimes,abnormal_etimes):\n",
    "    length = len(abnormal_stimes)\n",
    "    for i in range(length):\n",
    "        t1 = datetime.strptime(abnormal_stimes[i], '%M:%S').time()\n",
    "        t2 = datetime.strptime(abnormal_etimes[i], '%M:%S').time()\n",
    "        obj1 = timedelta(hours=t1.hour, minutes=t1.minute, seconds=t1.second)\n",
    "        obj2 = timedelta(hours=t2.hour, minutes=t2.minute, seconds=t2.second)\n",
    "        if (stime >= obj1 and etime <= obj2) or (stime < obj1 and etime > obj1) or (stime < obj2 and etime > obj2):\n",
    "            return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class labeling_objects:\n",
    "    def __init__(self,clip_no,stime,etime,label):\n",
    "        self.clip_no = clip_no\n",
    "        self.stime = stime\n",
    "        self.etime = etime\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_input(path,ann_file_path):\n",
    "    cap = cv.VideoCapture(path)\n",
    "    ret, frame1 = cap.read()\n",
    "\n",
    "    #reading first frame\n",
    "    prvs_gray = cv.cvtColor(frame1,cv.COLOR_BGR2GRAY)\n",
    "    width=prvs_gray.shape[1]\n",
    "    height = prvs_gray.shape[0]\n",
    "\n",
    "    prvs = cv.resize(prvs_gray,(int(width/10),int(height/10)),interpolation = cv.INTER_AREA)\n",
    "\n",
    "    #intializing all values\n",
    "    cnt=0\n",
    "    flow_array = []\n",
    "    mag_list = []\n",
    "    flow_array_array = [] #for storing all clips\n",
    "    secs = 0\n",
    "    clip = 0\n",
    "    label_objects_array = []\n",
    "    abnormal_stimes,abnormal_etimes = file_reading(ann_file_path)\n",
    "    \n",
    "    while(True):\n",
    "        ret, frame2 = cap.read()\n",
    "        cnt=cnt+1\n",
    "        if cnt%50 == 0:\n",
    "            flow_array_array.append(flow_array)\n",
    "            flow_array=[]\n",
    "            clip+=1\n",
    "            #adding labels here after one clip is recorded.\n",
    "            secs = secs+2\n",
    "            stime = timedelta(seconds = secs-2)\n",
    "            etime = timedelta(seconds = secs)\n",
    "            label = compare(stime,etime,abnormal_stimes,abnormal_etimes)\n",
    "            label_objects_array.append(labeling_objects(clip,stime,etime,label))\n",
    "            \n",
    "        if ret==False:\n",
    "            break\n",
    "\n",
    "        #converting frame into gray and resizing \n",
    "        gray2 = cv.cvtColor(frame2,cv.COLOR_BGR2GRAY)\n",
    "        next = cv.resize(gray2,(int(width/10),int(height/10)),interpolation = cv.INTER_AREA)\n",
    "\n",
    "        #calculating optical flow giving two consecutive frames as input\n",
    "        flow = cv.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "        # appending to the flow array\n",
    "        flow_array.append(flow)\n",
    "\n",
    "        #changing current frame as previous frame\n",
    "        prvs = next\n",
    "    if len(flow_array)!= 0:\n",
    "        flow_array_array.append(flow_array)\n",
    "        clip+=1\n",
    "        secs = secs+1\n",
    "        stime = timedelta(seconds = secs-1)\n",
    "        etime = timedelta(seconds = secs)\n",
    "        label = compare(stime,etime,abnormal_stimes,abnormal_etimes)\n",
    "        label_objects_array.append(labeling_objects(clip,stime,etime,label))\n",
    "    flow_array_length = len(flow_array_array)\n",
    "    print(\"Total no of clips\",flow_array_length)\n",
    "    print(\"total frames\",cnt)\n",
    "    \n",
    "    return flow_array_array,label_objects_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    \n",
    "    def __init__(self,X,k,weights,means,variances,n_iter):\n",
    "        self.X=X\n",
    "        self.k=k\n",
    "        self.weights=weights\n",
    "        self.means = means\n",
    "        self.variances = variances\n",
    "        self.eps=1e-8\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "    def run(self):\n",
    "        for step in range(self.n_iter):\n",
    "        \n",
    "            likelihood=[]\n",
    "            for j in range(self.k):\n",
    "                likelihood.append(self.pdf(self.X, self.means[j], np.sqrt(self.variances[j])))\n",
    "            likelihood = np.array(likelihood)\n",
    "            \n",
    "            b = []\n",
    "            # Maximization step \n",
    "            \n",
    "            for j in range(self.k):\n",
    "                # use the current values for the parameters to evaluate the posterior\n",
    "                # probabilities of the data to have been generanted by each gaussian    \n",
    "                b.append((likelihood[j] * self.weights[j]) / (np.sum([likelihood[i] * self.weights[i] for i in range(self.k)],axis=0))+self.eps)\n",
    "\n",
    "                # updage mean and variance\n",
    "                self.means[j] = np.sum(b[j] * self.X) / (np.sum(b[j]+self.eps))\n",
    "                self.variances[j] = np.sum(b[j] * np.square(self.X - self.means[j])) / (np.sum(b[j]+self.eps))\n",
    "                \n",
    "                #print(\"b dist=\",b[j])\n",
    "                # update the weights\n",
    "                self.weights[j] = np.mean(b[j])\n",
    "            #print(self.weights)\n",
    "            return self\n",
    "\n",
    "    def pdf(self,data,mean:float,variance:float):\n",
    "        s1 = 1/(np.sqrt(2*np.pi*variance))\n",
    "        s2 = np.exp(-(np.square(data - mean)/(2*variance)))\n",
    "        return s1*s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for distribution formation from the mag array of a clip\n",
    "def func_distribution_formation(arr):\n",
    "    dist_arr =[] \n",
    "    height,width,x=arr[0].shape\n",
    "    for idx in range(int(height)):\n",
    "        for j in range(int(width)):\n",
    "            dist=[]\n",
    "            for i in range(len(arr)):\n",
    "                dist.append(arr[i][idx,j])\n",
    "            dist=np.asarray(dist)\n",
    "            dist_arr.append(dist)\n",
    "    dist_arr=np.asarray(dist_arr)\n",
    "    return dist_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intial parameters for em clustering \n",
    "def intial_parameters(arr):\n",
    "    k=4\n",
    "    arr = np.asarray(arr)\n",
    "    intial_weights = [(1-0.1)/4 for i in range(k)]\n",
    "    intial_weights = np.append(intial_weights,0.1) # adding extra weight element for background purpose\n",
    "    means = np.random.choice(arr.flatten(),(k,2))\n",
    "    means =np.append(means,[0,0]) # adding extra mean element for background purpose\n",
    "\n",
    "    cov = np.random.sample(size=k)\n",
    "    cov = np.append(cov,4.0) # adding extra cov element for background purpose\n",
    "    return k,intial_weights,means,cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_objects:\n",
    "    def __init__(self,clip_no,stime,etime,weights_data,label):\n",
    "        self.clip_no = clip_no\n",
    "        self.stime = stime\n",
    "        self.etime = etime\n",
    "        self.weights_data = weights_data\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to run video input,distribution formation and input to GMM and get updated weights as output\n",
    "def run(path,ann_file_path):\n",
    "    mag_arr_all_clips,loa = video_input(path,ann_file_path)\n",
    "    k,initial_weights,means,cov = intial_parameters(mag_arr_all_clips[0])\n",
    "    data_object_array=[]\n",
    "    for index in range(len(mag_arr_all_clips)):\n",
    "        updated_weights=[]\n",
    "        updated_means=[]\n",
    "        updated_variances=[]\n",
    "        dist_arr = func_distribution_formation(mag_arr_all_clips[index])\n",
    "        for i in range(dist_arr.shape[0]):\n",
    "            gmm = GMM(dist_arr[i],k+1,initial_weights.copy(),means.copy(),cov.copy(),50)\n",
    "            gmm.run()\n",
    "            updated_weights.append(gmm.weights)\n",
    "            updated_means.append(gmm.means)\n",
    "            updated_variances.append(gmm.variances)\n",
    "        data_object_array.append(data_objects(loa[index].clip_no,loa[index].stime,loa[index].etime,np.asarray(updated_weights).flatten(),loa[index].label))        \n",
    "    return data_object_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of clips 1327\n",
      "total frames 66324\n"
     ]
    }
   ],
   "source": [
    "#running our entire code.\n",
    "ann_file_path = \"E:\\\\Study\\\\Sem Project\\\\Data\\\\abnormal_times.txt\"\n",
    "path = \"E:\\\\Study\\\\Sem Project\\\\Data\\\\traffic-junction.avi\"\n",
    "total_data_objects = run(path,ann_file_path) #path to video and path to annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total no of objects 1327\n",
      "clip no= 1\n",
      "start time= 0:00:00\n",
      "end time= 0:00:02\n",
      "weights = [0.23775831 0.21021411 0.23205344 ... 0.23086858 0.24774176 0.06312307]\n",
      "label =  -1 \n",
      "\n",
      "clip no= 2\n",
      "start time= 0:00:02\n",
      "end time= 0:00:04\n",
      "weights = [0.23794439 0.21014059 0.23198968 ... 0.23168734 0.25006667 0.06248911]\n",
      "label =  -1 \n",
      "\n",
      "clip no= 3\n",
      "start time= 0:00:04\n",
      "end time= 0:00:06\n",
      "weights = [0.23807687 0.21008745 0.23194458 ... 0.23159105 0.24978963 0.0625677 ]\n",
      "label =  -1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing objects value.\n",
    "print(\"total no of objects\",len(total_data_objects))\n",
    "for i in range(3):\n",
    "    print(\"clip no=\",total_data_objects[i].clip_no)\n",
    "    print(\"start time=\",total_data_objects[i].stime)\n",
    "    print(\"end time=\",total_data_objects[i].etime)\n",
    "    print(\"weights =\",total_data_objects[i].weights_data)\n",
    "    print(\"label = \",total_data_objects[i].label,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#writing into the csv file\n",
    "with open(\"E:\\\\Study\\\\Sem Project\\\\Data\\\\weight_motion_vector_data.csv\",'w',newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for i in range(len(total_data_objects)):\n",
    "        llist=[]\n",
    "        llist.append(total_data_objects[i].clip_no)\n",
    "        llist.append(total_data_objects[i].stime)\n",
    "        llist.append(total_data_objects[i].etime)\n",
    "        llist.append(total_data_objects[i].label)\n",
    "        for j in range(len(total_data_objects[i].weights_data)):\n",
    "            llist.append(total_data_objects[i].weights_data[j])\n",
    "        writer.writerow(llist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
